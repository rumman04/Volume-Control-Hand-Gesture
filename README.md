# Volume-Control-Hand-Gesture

**Project Overview**

This project implements a gesture-based system for volume and media control using a webcam, computer vision, and machine learning. Users can control volume dynamically using the distance between thumb and index finger, mute/unmute with pinch gestures, and navigate media via swipe gestures.

**Key Features:**

Real-time gesture recognition using Mediapipe

Volume adjustment and mute/unmute control via PyCaw

Custom gesture learning using K-Nearest Neighbors (KNN)

Media player integration using VLC

Text-to-speech feedback for user-friendly interaction

**Technologies Used:**

Python

Mediapipe

OpenCV

PyCaw

pyttsx3

scikit-learn

VLC Media Player
